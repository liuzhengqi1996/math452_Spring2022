{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some classic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"https://cdnapisec.kaltura.com/p/2356971/sp/235697100/embedIframeJs/uiconf_id/41416911/partner_id/2356971?iframeembed=true&playerId=kaltura_player&entry_id=1_4ypfrwx9&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_a9sbj527\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10f26f6a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=\"https://cdnapisec.kaltura.com/p/2356971/sp/235697100/embedIframeJs/uiconf_id/41416911/partner_id/2356971?iframeembed=true&playerId=kaltura_player&entry_id=1_4ypfrwx9&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_a9sbj527\" ,width='800', height='500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the lecture notes here: [Notes](https://sites.psu.edu/math452/files/2022/02/D03ClassicCNNs_Video_Notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some classic CNN models\n",
    "-----------------------\n",
    "\n",
    "In this section, we will use these convolutional operations introduced\n",
    "above to give a brief description of some classic convolutional neural\n",
    "network (CNN) models. Firstly, CNNS are actually a class of special DNN\n",
    "models. Let us recall the DNN structure as:\n",
    "\n",
    "$$\n",
    "    \\begin{cases}f^{0}(x) & =x \\\\ f^{\\ell}(x) & =\\sigma\\left(\\theta^{\\ell}\\left(f^{\\ell-1}\\right)\\right) \\quad \\ell=1: L \\\\ f(x) & =W^{L} f^{L}+b^{L}\\end{cases}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\left(\\theta^{\\ell}\\left(f^{\\ell-1}\\right)=W^{\\ell} f^{\\ell-1}(x)+b^{\\ell} .\\right.$$\n",
    "So the key features of CNNs is\n",
    "\n",
    "1.  Replace the general linear mapping to be convolution operations with\n",
    "    multichannel.\n",
    "\n",
    "2.  Use multi-resolution of images as shown in the next diagram.\n",
    "\n",
    "![image](images/img1.png)\n",
    "\n",
    "Then we will introduce some classical architectures in convolution\n",
    "neural networks.\n",
    "\n",
    "### LeNet-5, AlexNet and VGG\n",
    "\n",
    "The LeNet-5, AlexNet and VGG  can be written as:\n",
    "\n",
    "```{prf:algorithm} $h$ = Classic CNN$(f;J,v_1,\\cdots,v_J)$\n",
    ":label: al43_1\n",
    "\n",
    "**Initialization** $f^{1,0} = f_{in}(f)$.\n",
    "\n",
    "**For** $l = i:J$ do\n",
    "\n",
    "**For** $i = 1:v_l$ do\n",
    "\n",
    "Basic Block:\n",
    "    \n",
    "$$\n",
    "    f^{l,i} = \\sigma(\\theta^{l,i} * f^{l,i-1} )\n",
    "$$\n",
    "\n",
    "**EndFor**\n",
    "\n",
    "Pooling(Restriction):\n",
    "\n",
    "$$\n",
    "    f^{l+1,0} = R_{l}^{l+1} * f^{l,v_l}\n",
    "$$\n",
    "\n",
    "**EndFor**\n",
    "\n",
    "Final average pooling layer: $h = R_{ave}(f^{L,v_l})$\n",
    "\n",
    "```\n",
    "\n",
    "Here $R_{\\ell}^{\\ell+1} *_{2}$ represents for the pooling operation to\n",
    "sub-sampling these tensors into coarse spatial level (lower resolution).\n",
    "Here we use $R_{\\ell}^{\\ell+1} *_{2}$ to stand for the pooling\n",
    "operation. In general we can also have\n",
    "\n",
    "-   average pooling: fixed kernels such as\n",
    "\n",
    "$$\n",
    "    R_{\\ell}^{\\ell+1}=\\frac{1}{9}\\left(\\begin{array}{lll}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "-   Max pooling $R_{\\max }$ as discussed before.\n",
    "\n",
    "In these three classic CNN models, they still need some extra fully\n",
    "connected layers after $h$ as the output of CNNs. After few layers of\n",
    "fully connected layers, the model is completed by following a\n",
    "multi-class logistic regression model.\n",
    "\n",
    "These fully connected layers are removed in ResNet to be described\n",
    "below.\n",
    "\n",
    "### ResNet\n",
    "\n",
    "The original ResNet  is one of the most popular CNN\n",
    "architectures in image classification problems.\n",
    "\n",
    "```{prf:algorithm} $h = ResNet(f;J,v_1,\\cdots,v_J)$\n",
    ":label: al43_2\n",
    "**Initialization** $r^{1,0} = f_{in}(f)$\n",
    "\n",
    "**For** $l = 1 : J$ do\n",
    "\n",
    "**For** $i=1:v_l$ do\n",
    "    \n",
    "Basic Block:\n",
    "        \n",
    "$$\n",
    "    r^{\\ell, i}=\\sigma\\left(r^{\\ell, i-1}+A^{\\ell, i} * \\sigma \\circ B^{\\ell, i} * r^{\\ell, i-1}\\right)\n",
    "$$\n",
    "        \n",
    "**EndFor**\n",
    "\n",
    "Pooling(Restriction):\n",
    "\n",
    "$$\n",
    "    r^{\\ell+1,0}=\\sigma\\left(R_{\\ell}^{\\ell+1} *_{2} r^{\\ell, v_{\\ell}}+A^{\\ell+1,0} \\circ \\sigma \\circ B^{\\ell+1,0} *_{2} r^{\\ell, v_{\\ell}}\\right) .\n",
    "$$\n",
    "\n",
    "**EndFor**\n",
    "\n",
    "Final average pooling layer: $h=R_{ave }\\left(r^{L, v_{t}}\\right)$.\n",
    "\n",
    "        \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Here $f_{\\text {in }}(\\cdot)$ may depend on different data set and\n",
    "problems such as $f_{\\text {in }}(f)=\\sigma \\circ \\theta^{0} * f$ for\n",
    "CIFAR and\n",
    "$f_{\\text {in }}(f)=R_{\\max } \\circ \\sigma \\circ \\theta^{0} * f$ for\n",
    "ImageNet \\[1\\] as in \\[3\\]. In addition\n",
    "$r^{\\ell, i}=r^{\\ell, i-1}+A^{\\ell, i} * \\sigma \\circ B^{\\ell, i} * \\sigma\\left(r^{i-1}\\right)$\n",
    "is often called the basic ResNet block. Here, $A^{\\ell, i}$ with\n",
    "$i \\geq 0$ and $B^{\\ell, i}$ with $i \\geq 1$ are general $3 \\times 3$\n",
    "convolutions with zero padding and stride 1. In pooling block, $*_{2}$\n",
    "means convolution with stride 2 and $B^{\\ell, 0}$ is taken as the\n",
    "$3 \\times 3$ kernel with same output channel dimension of\n",
    "$R_{\\ell}^{\\ell+1}$ which is taken as $1 \\times 1$ kernel and called as\n",
    "projection operator. During two consecutive pooling blocks,\n",
    "index $\\ell$ means the fixed resolution or we $\\ell$-th grid level as in\n",
    "multigrid methods. Finally, $R_{\\mathrm{ave}}$ $\\left(R_{\\max }\\right)$\n",
    "means average (max) pooling with different strides which is also\n",
    "dependent on datasets and problems.\n",
    "\n",
    "3 pre-act ResNet\n",
    "----------------\n",
    "\n",
    "The pre-act ResNet shares a similar structure with ResNet.\n",
    "\n",
    "```{prf:algorithm} $h = pre-act ResNet(f;J,v_1,\\cdots,v_J)$\n",
    "\n",
    "**Initialization** $r^{1,0} = f_{in}f$\n",
    "\n",
    "**For** $l = 1:J$ do\n",
    "\n",
    "**For** $i = 1:v_l$ do\n",
    "\n",
    "Basic Block:\n",
    "\n",
    "$$\n",
    "    r^{l,i} = r^{l,i-1} + A^{l,i} * \\sigma \\circ B^{l.i} * \\sigma(r^{l,i-1})\n",
    "$$\n",
    "\n",
    "**EndFor**\n",
    "\n",
    "Pooling(Restriction):\n",
    "\n",
    "$$\n",
    "    r^{l+1,0} = R_{l}^{l+1} * r^{l,v_l} + A^{l+1,0} \\circ \\sigma \\circ B^{l+1,0} * \\sigma(r^{l,v_l}) \n",
    "$$\n",
    "```\n",
    "\n",
    "Here pre-act ResNet share almost the same setup with ResNet.\n",
    "\n",
    "The only difference between ResNet and pre-act ResNet can be viewed as\n",
    "putting a $\\sigma$ in different places. The connection of those three\n",
    "models are often shown with next diagrams:\n",
    "\n",
    "Without loss of generality, we extract the key feedforward steps on the\n",
    "same grid in different CNN models as follows.\n",
    "\n",
    "\n",
    "![image](images/img3.png)\n",
    "\n",
    "Fig. Comparison of CNN Structures\n",
    "\n",
    "Classic CNN\n",
    "\n",
    "$$\n",
    "    f^{\\ell, i}=\\xi^{i} \\circ \\sigma\\left(f^{\\ell, i-1}\\right) \\quad \\text { or } \\quad f^{\\ell, i}=\\sigma \\circ \\xi^{i}\\left(f^{\\ell, i-1}\\right)\n",
    "$$\n",
    "\n",
    "ResNet\n",
    "\n",
    "$$\n",
    "    r^{\\ell, i}=\\sigma\\left(r^{\\ell, i-1}+\\xi^{\\ell, i} \\circ \\sigma \\circ \\eta^{\\ell, i}\\left(r^{\\ell, i-1}\\right)\\right)\n",
    "$$\n",
    "\n",
    "pre-act ResNet\n",
    "\n",
    "$$\n",
    "    r^{\\ell, i}=r^{\\ell, i-1}+\\xi^{\\ell, i} \\circ \\sigma \\circ \\eta^{\\ell, i} \\circ \\sigma\\left(r^{\\ell, i-1}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
