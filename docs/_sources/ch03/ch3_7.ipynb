{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7 Basic Statistical Learning Theory\n",
    "\n",
    "-   Goal: Estimate an unknown probability distribution $D$ on a set $X$\n",
    "    from samples $(i,i,d)$ $x_{1}, \\ldots, x_{n} \\in X$\n",
    "\n",
    "-   Introduce a family of distributions $P_{\\theta}$ for\n",
    "    $\\theta \\in \\Theta$ and try to choose $\\theta$ to \\\"match\\\" the\n",
    "    samples.\n",
    "\n",
    "   -   Maximum Likelihood Estimate: Choose $\\theta$ to maximize the\n",
    "        probability of the samples.\n",
    "\n",
    "   -   Example: Let $X=R$, have some samples $x_{1}, \\ldots, x_{n}$\n",
    "        drawn from a distribution D, say $P_{\\theta}$ is a Gaussian with\n",
    "        variance 1, centered at $\\theta \\in \\mathbb{R}=\\Theta$, i.e.\n",
    "        density\n",
    "        $p_{\\theta}(x)=\\frac{1}{\\sqrt{2 \\pi}} e^{-(x-\\theta)^{2} / 2}$\n",
    "\n",
    "        ![image](../figures/probabilityLR2.png){width=\".55\\\\textwidth\"}\n",
    "\n",
    "   -   Use the samples to find the center $\\theta$.\n",
    "\n",
    "## 3.7.1 Maximum Likelihood Estimate(MLE)\n",
    "\n",
    "-   Given $\\theta \\in \\Theta (=\\mathbb{R}$ for this example), what is\n",
    "    the probability of the data $\\left\\{x_{j}\\right\\}_{j=1}^{n}$?\n",
    "\n",
    "   -   Samles independent: Likelihood function(as a function of\n",
    "        $\\sigma$)\n",
    "        \n",
    "        $$\n",
    "            P_{\\theta}\\left(\\left\\{x_{j}\\right\\}_{j=1}^{n}\\right)=\\prod_{j=1}^{n} p_{\\theta}\\left(x_{j}\\right)\n",
    "                =\\frac{1}{(\\sqrt{2 \\pi})^{n}}\\prod_{j=1}^{n} e^{-\\left(x_{j}-\\theta\\right)^{2} / 2}\n",
    "                =\\frac{1}{(2 \\pi)^{n/ 2}} e^{-\\sum_{j=1}^{n}\\left(x_{j}-\\theta\\right)^{2} / 2}\n",
    "        $$\n",
    "\n",
    "   -   MLE: Choose $\\theta$ to maximize this!\n",
    "\n",
    "   -   Often it's useful to consider log likelihood function\n",
    "        $\\log \\left(P_{\\theta}\\left(\\left\\{x_{j}\\right\\}_{j=1}^{n}\\right)\\right)$\n",
    "        \n",
    "        $$\\begin{aligned} \\theta^{*}= \\operatorname{argmax} _{\\theta \\in \\Theta}\\log \\left(P_{\\theta}\\left(\\left\\{x_{j}\\right\\}_{j=1}^{n}\\right)\\right) \\\\\n",
    "                \\left(\\operatorname{argmin} _{\\theta \\in \\Theta}-\\log \\left(P_{\\theta}\\left(\\left\\{x_{j}\\right\\}_{j=1}^{n}\\right)\\right)\\right) \\end{aligned}\n",
    "        $$\n",
    "\n",
    "-   For this example:\n",
    "\n",
    "    $$\n",
    "        \\log \\left(P_{\\theta}\\left(\\left\\{x_{j}\\right\\}_{j=1}^{n}\\right)\\right)=-\\log (2 \\pi) \\cdot\\left(\\frac{n}{2}\\right)-\\sum_{j=1}^{n} \\frac{\\left(x_{j}-\\theta\\right)^{2}}{2}\n",
    "    $$\n",
    "    \n",
    "    $$\n",
    "        \\theta^{*}=\\operatorname{argmin}_{\\theta \\in \\mathbb{R}} \\sum_{j=1}^{n} \\frac{\\left(x_{j}-\\theta\\right)^{2}}{2}.\n",
    "    $$\n",
    "    \n",
    "    $$\n",
    "        \\theta^{*}=\\frac{1}{n} \\sum_{j=1}^{n} x_{j}.\n",
    "    $$\n",
    "\n",
    "    ![image](../figures/probabilityLR3.png){width=\".55\\\\textwidth\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
