
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nonlinear models &#8212; Math 452 Site</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Polynomials and Weierstrass theorem" href="../m3_02/m3_02.html" />
    <link rel="prev" title="Module 3: Deep neural networks" href="../module3_.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/PSU_SCI_RGB_2C.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Math 452 Site</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome to Math 452
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  contents
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module0/ch0_.html">
   Module 0 Get started: course information and preparations:
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module0/ch0_1.html">
     Course information, requirements and reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module0/ch0_2.html">
     Course background and introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module0/ch0_3.html">
     Introduction to Python and Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module0/quiz0.html">
     Preliminary Quiz
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module1/module1_.html">
   Module 1: Linear machine learning models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_01.html">
     Machine learning basics, popular data sets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_02.html">
     Linearly separable sets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_03.html">
     Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_04.html">
     KL-divergence and cross-entropy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_05.html">
     Support vector machine and relation with LR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_06.html">
     Optimization and gradient descent method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_hw.html">
     Homework 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/Programming_Assignment_1.html">
     Module 1 Programming Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/quiz1.html">
     Quiz 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module2/module2_.html">
   Module 2: Probability and training algorithms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_01.html">
     Introduction to probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_02.html">
     Probabilistic derivation of logistic regression models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_03/m2_03.html">
     Convex functions and convergence of gradient descen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_04.html">
     Stochastic gradient descent method and convergence theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_05.html">
     MNIST: training and generalization accuracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_hw.html">
     Homework 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/Programming_Assignment_2.html">
     Week 2 Programming Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/quiz2.html">
     Quiz 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../module3_.html">
   Module 3: Deep neural networks
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Nonlinear models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m3_02/m3_02.html">
     Polynomials and Weierstrass theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m3_03/m3_03.html">
     Finite element method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m3_04/m3_04.html">
     Deep neural network functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m3_05/m3_05.html">
     Universal approximation properties
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m3_06.html">
     Application to data classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m3_07.html">
     DNN for image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m3_08/m3_08.html">
     Monte Carlo Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../C08_DNN.html">
     Building and Training Deep Neural Networks (DNNs) with Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m3_hw.html">
     Homework 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Programming_Assignment_3.html">
     Week 3 Programming Assignment
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module4/module4_.html">
   Module 4: Convolutional neural networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module4/m4_01/m4_01.html">
     Convolutional neural networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module4/m4_02/m4_02.html">
     Convolutional operations on images
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module4/m4_03/m4_03.html">
     Some classic CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module4/m4_04/m4_04.html">
     Training CNN with GPU on Colab
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module4/m4_05.html">
     Building and Training Convolutional Neural Networks (CNNs) with Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module4/m4_hw.html">
     Homework 4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module4/Programming_Assignment_4.html">
     Week 4 Programming Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module4/quiz4.html">
     Quiz 4
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module5/module5_.html">
   Module 5: Normalization, ResNet and Multigrid
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_01/m5_01.html">
     Data normalization and weights initialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_02/m5_02.html">
     Batch normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_03/m5_03.html">
     Building and Training ResNet with Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_04/m5_04.html">
     Multigrid Method for Finite Element
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_hw.html">
     Homework 5
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/Programming_Assignment_5.html">
     Week 5 Programming Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/quiz5.html">
     Quiz 5
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module6/module6_.html">
   Module 6: MgNet
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module6/m6_01.html">
     MgNet: a special CNN based on multigrid method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module6/m6_02.html">
     Multigrid and MgNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module6/MG_MgNet.html">
     Multigrid and MgNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module6/Final_Project.html">
     MATH 497: Final Project
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/Module3/m3_01/m3_01.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/liuzhengqi1996/math452_Spring2022/main?urlpath=lab/tree/Module3/m3_01/m3_01.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-the-lecture-notes-here-notes">
   Download the lecture notes here: Notes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nonlinear-classifiable-sets">
   Nonlinear classifiable sets
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="nonlinear-models">
<h1>Nonlinear models<a class="headerlink" href="#nonlinear-models" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>

<span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://cdnapisec.kaltura.com/p/2356971/sp/235697100/embedIframeJs/uiconf_id/41416911/partner_id/2356971?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=1_mpdchgne&amp;flashvars[streamerType]=auto&amp;amp;flashvars[localizationCode]=en&amp;amp;flashvars[leadWithHTML5]=true&amp;amp;flashvars[sideBarContainer.plugin]=true&amp;amp;flashvars[sideBarContainer.position]=left&amp;amp;flashvars[sideBarContainer.clickToClose]=true&amp;amp;flashvars[chapters.plugin]=true&amp;amp;flashvars[chapters.layout]=vertical&amp;amp;flashvars[chapters.thumbnailRotator]=false&amp;amp;flashvars[streamSelector.plugin]=true&amp;amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;amp;flashvars[dualScreen.plugin]=true&amp;amp;flashvars[hotspots.plugin]=1&amp;amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;amp;&amp;wid=1_fam1ya2z&quot;</span> <span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="s1">&#39;800&#39;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="s1">&#39;500&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="800"
    height="500"
    src="https://cdnapisec.kaltura.com/p/2356971/sp/235697100/embedIframeJs/uiconf_id/41416911/partner_id/2356971?iframeembed=true&playerId=kaltura_player&entry_id=1_mpdchgne&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_fam1ya2z"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<div class="section" id="download-the-lecture-notes-here-notes">
<h2>Download the lecture notes here: <a class="reference external" href="https://sites.psu.edu/math452/files/2022/01/C01_-Nonlinear-Models-1.pdf">Notes</a><a class="headerlink" href="#download-the-lecture-notes-here-notes" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="nonlinear-classifiable-sets">
<h2>Nonlinear classifiable sets<a class="headerlink" href="#nonlinear-classifiable-sets" title="Permalink to this headline">¶</a></h2>
<p>In the section, we will extend the linearly separable sets to nonlinear
case. A natural extension is like what kernel method does in SVM for
binary case, we will introduce the so-called feature mapping.</p>
<p>Thus, we have the following natural extension for linearly separable by
using feature mapping and original definition of linearly separable.</p>
<div class="proof definition admonition" id="definition-0">
<p class="admonition-title"><span class="caption-number">Definition 4 </span> (nonlinearly separable sets)</p>
<div class="definition-content section" id="proof-content">
<p>These data sets</p>
<div class="math notranslate nohighlight">
\[
    A_{1}, A_{2}, \cdots, A_{k} \subset \mathbb{R}^{d}
\]</div>
<p>are called nonlinearly separable, if there exist a feature space <span class="math notranslate nohighlight">\(\mathbb{R}^{\tilde{d}}\)</span></p>
<p>and a smooth (if it has derivatives of all orders) feature mapping</p>
<div class="math notranslate nohighlight">
\[
    \varphi: \mathbb{R}^{d} \mapsto \mathbb{R}^{d}
\]</div>
<p>such that</p>
<div class="math notranslate nohighlight">
\[
    \tilde{A}_{i}:=\varphi\left(A_{i}\right)=\left\{\tilde{x} \mid \tilde{x}=\varphi(x), x \in A_{i}\right\},\quad i=1,2, \ldots, k
\]</div>
<p>are linearly separable.</p>
</div>
</div><div class="admonition-remark admonition">
<p class="admonition-title">Remark</p>
<p>1-  This definition is also consistent with the definition of
linearly separable as we can just take  <span class="math notranslate nohighlight">\(\tilde{d}=d\)</span> and <span class="math notranslate nohighlight">\(\varphi= id\)</span> if <span class="math notranslate nohighlight">\(A_{1}, A_{2}, \cdots, A_{k}\)</span></p>
<p>are already linearly separable.</p>
<p>2-  The kernel method in SVM is mainly based on this idea for binary case <span class="math notranslate nohighlight">\((\mathrm{k}=2)\)</span> where they use kernel functions to approximate this <span class="math notranslate nohighlight">\(\varphi(x)\)</span></p>
<p>3-  For most commonly used deep learning models, they are all associated with a softmax mapping which means that we can interpret these deep learning models as the approximation for feature mapping <span class="math notranslate nohighlight">\(\varphi\)</span></p>
</div>
<p>However, softmax is not so crucial for this definition actually as we
have the next equivalent result.</p>
<div class="proof theorem admonition" id="thm31_1">
<p class="admonition-title"><span class="caption-number">Theorem 3 </span></p>
<div class="theorem-content section" id="proof-content">
<p><span class="math notranslate nohighlight">\(A_{1}, A_{2}, \cdots, A_{k} \subset \mathbb{R}^{d}\)</span> are nonlinearly separable is equivalent that there there exist a smooth classification
function</p>
<div class="math notranslate nohighlight">
\[
    \psi: \mathbb{R}^{d} \mapsto \mathbb{R}^{k}
\]</div>
<p>such that for all <span class="math notranslate nohighlight">\(i=1: k\)</span></p>
<p>and <span class="math notranslate nohighlight">\(j \neq i\)</span></p>
<div class="math notranslate nohighlight">
\[
    \psi_{i}(x)&gt;\psi_{j}(x), \quad \forall x \in A_{i}
\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. On the one
hand, it is easy to see that if <span class="math notranslate nohighlight">\(A_{1}, A_{2}, \cdots, A_{k} \subset \mathbb{R}^{d}\)</span></p>
<p>are nonlinearly separable then they we can just take</p>
<div class="math notranslate nohighlight">
\[
    \psi(x)=p(\varphi(x) ; \theta)
\]</div>
<p>where the  <span class="math notranslate nohighlight">\(\boldsymbol{p}(y ; \theta)\)</span></p>
<p>is the softmax function for linearly separable sets <span class="math notranslate nohighlight">\(\varphi\left(A_{i}\right)\)</span> for
<span class="math notranslate nohighlight">\(i = 1,2, \cdots, k\)</span></p>
<p>On the other hand, let assume that <span class="math notranslate nohighlight">\(\psi\)</span></p>
<p>is the smooth classification functions for  <span class="math notranslate nohighlight">\(A_{1}, A_{2}, \cdots, A_{k} \subset \mathbb{R}^{d} \)</span></p>
<p>We claim that, we can take <span class="math notranslate nohighlight">\(\varphi(x)=\psi(x)\)</span></p>
<p>and then</p>
<div class="math notranslate nohighlight">
\[
    \varphi\left(A_{1}\right), \varphi\left(A_{2}\right), \cdots, \varphi\left(A_{k}\right) \subset \mathbb{R}^{k} \quad(\tilde{d}=k)
\]</div>
<p>will be linearly separable. Actually, if you take <span class="math notranslate nohighlight">\(\theta=(I, 0)\)</span></p>
<p>in softmax mapping <span class="math notranslate nohighlight">\(\boldsymbol{p}(x ; \theta)\)</span> , then the monotonicity of <span class="math notranslate nohighlight">\(e^{x}\)</span></p>
<p>show that for all <span class="math notranslate nohighlight">\(i=1: k \)</span> and  <span class="math notranslate nohighlight">\(j \neq i \)</span></p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{p}_{i}(\varphi(x) ; \theta)=\frac{e^{\psi_{i}(x)}}{\sum_{i=1}^{k} e^{\psi_{i}(x)}}&gt;\frac{e^{\psi_{j}(x)}}{\sum_{i=1}^{k} e^{\psi_{i}(x)}}=\boldsymbol{p}_{j}(\varphi(x) ; \theta), \quad \forall x \in A_{i} .
\]</div>
</div>
<p>Similarly to linearly separable sets, we have the next lemme for <span class="math notranslate nohighlight">\(k=2\)</span></p>
<div class="proof lemma admonition" id="lemma1">
<p class="admonition-title"><span class="caption-number">Lemma 7 </span></p>
<div class="lemma-content section" id="proof-content">
<p><span class="math notranslate nohighlight">\(A _{1}\)</span> and <span class="math notranslate nohighlight">\(A_{2}\)</span> are nonlinearly separable is equivalent that there exists a function <span class="math notranslate nohighlight">\( \varphi: \mathbb{R}^{d} \mapsto \mathbb{R} \)</span> such that</p>
<div class="math notranslate nohighlight">
\[
    \varphi(x)&gt;0 \quad \forall x \in A_{1} \quad \text { and } \quad \varphi(x)&lt;0 \quad \forall x \in A_{2}
\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Based the equivalence of nonlinearly separable sets, there exists <span class="math notranslate nohighlight">\(\psi_{1}(x)\)</span> and <span class="math notranslate nohighlight">\(\psi_{2}(2)\)</span></p>
<p>such that for all <span class="math notranslate nohighlight">\(i=1: 2\)</span> and <span class="math notranslate nohighlight">\(j \neq i \)</span></p>
<div class="math notranslate nohighlight">
\[
    \psi_{i}(x)&gt;\psi_{j}(x), \quad \forall x \in A_{i}
\]</div>
<p>Then, we can just take</p>
<div class="math notranslate nohighlight">
\[
    \varphi(x)=\psi_{1}(x)-\psi_{2}(x)
\]</div>
<p>On the other hand, if there exist <span class="math notranslate nohighlight">\(\varphi(x)\)</span>, then we can construct <span class="math notranslate nohighlight">\(\psi_{1}(x)\)</span> and <span class="math notranslate nohighlight">\(\psi_{2}(2)\)</span> as</p>
<div class="math notranslate nohighlight">
\[
    \psi_{1}(x)=\frac{1}{2} \varphi(x) \quad \text { and } \quad \psi_{2}(x)=-\frac{2}{2} \varphi(x)
\]</div>
</div>
<div class="admonition-remark admonition">
<p class="admonition-title">Remark</p>
<p>Here we mention that, we only assume that for all <span class="math notranslate nohighlight">\(i=1: k\)</span> and <span class="math notranslate nohighlight">\(j \neq i\)</span> we have <span class="math notranslate nohighlight">\(\psi_{i}(x)&gt;\psi_{j}(x), \forall x \in A_{i}\)</span> for nonlinearly separable. We do not assume that <span class="math notranslate nohighlight">\(\psi_{i}(x) \geq 0\)</span> or <span class="math notranslate nohighlight">\(\sum_{i=1}^{k} \psi_{i}(x)=1\)</span> , which means that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \psi(x)=\left(\begin{array}{c}\psi_{1}(x) \\ \psi_{2}(x) \\ \vdots \\ \psi_{k}(x)\end{array}\right)
\end{split}\]</div>
<p>is not a discrete probability distribution over all k classes.</p>
</div>
<p>The previous theorem shows that softmax function is not so crucial in
nonlinearly separable case. Combined with deep learning models, we have
the following understanding about what deep learning models are
approximating.</p>
<ol class="simple">
<li><p>If a classification model is followed with a softmax, then the it is
approximating the feature mapping <span class="math notranslate nohighlight">\(\varphi: \mathbb{R}^{d} \mapsto \mathbb{R}^{\bar{d}}\)</span></p></li>
<li><p>If the classification model dose not followed by softmax, then it is
approximating <span class="math notranslate nohighlight">\(\psi: \mathbb{R}^{d} \mapsto \mathbb{R}^{k}\)</span> directly.</p></li>
</ol>
<p>Example. Consider <span class="math notranslate nohighlight">\(k=2\)</span> and <span class="math notranslate nohighlight">\(A_{1} \subset\left\{(x, y) \mid x^{2}+y^{2}&lt;1\right\}, \quad A_{2} \subset\left\{(x, y) \mid x^{2}+y^{2}&gt;1\right\}\)</span>, then we can have the following nonlinear feature mapping:</p>
<p><img alt="image" src="../../_images/img1.png" /></p>
<p>Here we have the following comparison for linear and nonlinear models
from the viewpoint of loss functions:</p>
<p>Linear case (Logistic regression):</p>
<div class="math notranslate nohighlight">
\[
    L_{\lambda}(\theta)=\sum_{j=1}^{N} \ell\left(y_{j}, p\left(x_{j} ; \theta\right)\right)+\lambda R(\|\theta\|)
\]</div>
<p>Nonlinear case:</p>
<div class="math notranslate nohighlight">
\[
    L_{\lambda}(\theta)=\sum_{j=1}^{N} \ell\left(y_{j}, p\left(\varphi\left(x_{j} ; \theta_{1}\right) ; \theta_{2}\right)\right)+\lambda R(\|\theta\|)
\]</div>
<p>We have the following remarks:</p>
<div class="admonition-remark admonition">
<p class="admonition-title">Remark</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(\ell(q, p)=\sum_{i=1}^{k}-q_{i} \log p_{i} \leftrightarrow \text { cross-entropy }\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p(x ; \theta)=\operatorname{softmax}(W x+b)\)</span> where <span class="math notranslate nohighlight">\(\theta=(W, b)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\theta=\left(\theta_{1}, \theta_{2}\right)\)</span> for nonlinear case</p></li>
<li><p><span class="math notranslate nohighlight">\(\lambda R(\|\theta\|) \leftrightarrow\)</span> regularization term</p></li>
</ol>
</div>
<p>In general, we have the following popular nonlinear models for <span class="math notranslate nohighlight">\(\varphi(x ; \theta)\)</span></p>
<ol class="simple">
<li><p>Polynomials.</p></li>
<li><p>Piecewise polynomials (finite element method).</p></li>
<li><p>Kernel functions in SVM.</p></li>
<li><p>Deep neural networks.</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "liuzhengqi1996/math452_Spring2022",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Module3/m3_01"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="../module3_.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Module 3: Deep neural networks</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="../m3_02/m3_02.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Polynomials and Weierstrass theorem</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Department of Mathematics, Penn State University Park<br/>
        
            &copy; Copyright The Pennsylvania State University, 2021. This material is not licensed for resale.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>