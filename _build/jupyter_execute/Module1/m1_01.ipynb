{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning basics, popular data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe\n",
       "    width=\"800\"\n",
       "    height=\"500\"\n",
       "    src=\"https://cdnapisec.kaltura.com/p/2356971/sp/235697100/embedIframeJs/uiconf_id/41416911/partner_id/2356971?iframeembed=true&playerId=kaltura_player&entry_id=1_z2ldie17&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[mediaProxy.mediaPlayFrom]=0&amp;flashvars[mediaProxy.mediaPlayTo]=600&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_27z0chwl\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe27667e040>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=\"https://cdnapisec.kaltura.com/p/2356971/sp/235697100/embedIframeJs/uiconf_id/41416911/partner_id/2356971?iframeembed=true&playerId=kaltura_player&entry_id=1_z2ldie17&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[hotspots.plugin]=1&amp;flashvars[mediaProxy.mediaPlayFrom]=0&amp;flashvars[mediaProxy.mediaPlayTo]=600&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&wid=1_27z0chwl\" ,width='800', height='500')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the lecture notes here: [Notes](https://sites.psu.edu/math452/files/2021/12/A01ClassificationProblem_Video_Notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A basic machine learning problem: image classification\n",
    "Can a machine (function) tell the difference ?\n",
    "```{image} /figures/cat-dog-1.png\n",
    ":name: label1_1\n",
    ":height: 150px\n",
    "```\n",
    " Mathematically, gray-scale image can be just taken as matrix in $R^{n_0\\times n_0}$.\n",
    " ```{image} /figures/gray-1.png\n",
    ":height: 250px\n",
    "```\n",
    " The next figure shows different result from: human vision and computer representation: \n",
    " ```{image} /figures/ImagePixels.png\n",
    ":name: label1_2\n",
    ":height: 150px\n",
    "```\n",
    " An image is just a big grid of numbers between [0,255]\n",
    "  e.g. $800 \\times 600 \\times 3$ (3 channels RGB)\n",
    "\n",
    " Futhermore, color image can be taken as 3D tensor (matrix with 3 channel(RGB) ) in $R^{n_0\\times n_0 \\times 3}$.\n",
    " ```{image} /figures/corlor-1.png\n",
    ":name: label1_3\n",
    ":height: 150px\n",
    "```\n",
    "\n",
    "Supervised learning\n",
    "Then, let us think about the general supervised learning case.\n",
    "\n",
    " Each image = a big vector of pixel values\n",
    "\n",
    " - $d = 1280\\times 720 \\times 3$(width $\\times$ height $\\times$ RGB channel) \n",
    " \n",
    "\n",
    "\n",
    "3 different sets of points in $\\mathbb{R}^d$, are they separable?\n",
    "```{image} /figures/cat-dog-2.png\n",
    ":height: 250px\n",
    "```\n",
    "```{image} /figures/cat-dog-3.png\n",
    ":height: 250px\n",
    "```\n",
    "\n",
    "- Mathematical problem\n",
    "Find $f(\\cdot; \\theta): \\mathbb{R}^d \\to \\mathbb{R}^3$ such that: \n",
    "        \n",
    "$f(cat,\\theta) \\approx \\begin{pmatrix}\n",
    "\t1\\\\ 0 \\\\ 0 \n",
    "\t\\end{pmatrix} $\n",
    "    \n",
    "$f(dog,\\theta)\\approx \\begin{pmatrix}\n",
    "\t0\\\\ 1 \\\\ 0 \n",
    "\t\\end{pmatrix} \n",
    "    $\n",
    "    \n",
    "$\n",
    "f(rabbit,\\theta)\n",
    "\\approx \n",
    "\t\\begin{pmatrix}\n",
    "\t0\\\\ 0 \\\\ 1\n",
    "\t\\end{pmatrix} \n",
    "$\n",
    "- Function interpolation\n",
    "- Data fitting\n",
    "\n",
    "### Formulate “learning”\n",
    "- Data: $\\{x_j, y_j\\}_{j=1}^N$\n",
    "- Find $f^*$ in some function class s.t. $f^*(x_j) \\approx y_j$.\n",
    "- Mathematically, solve the optimization problem by parameterizing the abstract function class\n",
    "$\n",
    "\t\\min_{\\theta} \\mathcal L(\\theta)\n",
    "$\n",
    "\n",
    "where\n",
    "$\n",
    "\t\t\\mathcal L( \\theta):=\n",
    "\t\t{\\mathbb E}_{(x,y)\\sim \\mathcal D}[\\ell(f(x;  \\theta), y)]\\approx L( \\theta) :=\n",
    "\t\t\\frac{1}{N} \\sum_{j=1}^N\\ell(y_j, f(x_j;  \\theta))\n",
    "$\n",
    "\n",
    "Here\n",
    "$\n",
    "\\ell(y_j,f(x_j;  \\theta))\n",
    "$ \n",
    "is a  general distance between real label $y_j$ and predicted label $f(x_j;\\theta)$\n",
    "\n",
    "Two commonly used distances are \n",
    "- $l^2$ distance: \n",
    "$\n",
    "\t\t\\ell(y_j,f(x_j; \\theta)) = \\|y_j - f(x_j; \\theta)\\|^2.\n",
    "$\t\t\n",
    "- KL-divergence distance:\n",
    "$\n",
    "\\ell(y_j, f(x_j;  \\theta)) = \\sum_{i=1}^k [y_j]_i \\log\\frac{[y_j]_i }{[f(x_j; \\theta)]_i}.\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image classification problem \n",
    "### Image classification problem \n",
    "We consider a basic machine learning problem for classifying a collection of images\n",
    "into k distinctive classes. As an example, we consider a two-dimensional image\n",
    "which is usually represented by a tensor $x \\in R^{n_0\\times n_0 \\times c} = R^d$\n",
    "Here $n_0 \\times n_0$ is the original image resolutuon and\n",
    "\n",
    "$\n",
    "c=\n",
    "\t\\left \\{\n",
    "\t\\begin{array}[rl]{rl}\n",
    "\t1 & \\mbox{for grayscale image},\\\\    \n",
    "\t3 & \\mbox{for color image}.\n",
    "\t\\end{array}\n",
    "\t\\right.\n",
    "$\n",
    "\n",
    "A typical supervised machine learning problem begins with a data set (training\n",
    "data)\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "D &= \\{(x_j, y_j)\\}_{j=1}^N, \\quad \\text{and} \\quad A = \\{ x_1, x_2, \\cdots, x_N\\}  \\\\\n",
    "A &= A_1\\cup A_2\\cup \\cdots \\cup A_k, ~A_i\\cap A_j = \\emptyset, \\forall i \\neq j\n",
    "\\end{aligned}\n",
    "$\n",
    "and $y_j \\in R^k$ is the label for data $x_j$, with $y_i[i]$ as the probability for $x_i$ in classes $i$ or $x_j \\in A_i$.\n",
    "Here for image classification problem, $y_j = e_{i_j}$, \n",
    "if $x_j \\in A_{i_j}$ or we say $x_j$ has real label $i_j$.\n",
    "Roughly speaking, a supervised learning problem can be thought as a data fitting\n",
    "problem in a high dimensional space $R^d$. \n",
    "Namely, we need to find a mapping such that, for any $x_j \\in A$\n",
    "$\n",
    "f(x_j)\\approx y_j = e_{i_j} \\in \\mathbb R^k.\n",
    "$\n",
    "\n",
    "\n",
    "for data $x_j \\in A$. For general setting above, we use a probatillistic model for understanding the output $f(x) \\in R^k$ as a discrete distribution on $\\{1,\\cdots ,k\\}$,\n",
    "with $[f(x)]_{i}$ as the probability for x in the class i, namely\n",
    "$\n",
    "0 \\leq [f(x)]_i \\leq 1\n",
    "$, \n",
    "$\n",
    "\\sum_{i=1}^{k}[f(x)]_{i} =1\n",
    "$.\n",
    "At last, we finish our model with a simple strategy to choose \n",
    "$\n",
    "argmax_i\\{ [f(x)]_i :  i = 1:k\\}\n",
    "$\n",
    "as the label for a test data $x$, which ideally is close to . The remaining key issue is the construction of the classification mapping $f$.\n",
    "Generally speaking, there will be a test set\n",
    "$T = \\{(x_j,y_j)\\}_{j=1}^{M}$,\n",
    "with the same dimension of training data $D$, but is not known before we finish the\n",
    "training process. That is to say, we can use this test data $T$ to verify the performance\n",
    "of trained model $f$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Some popular data sets in image classification \n",
    "\n",
    "In this subsection, we will introduce some popular and standard data sets in image\n",
    "classification.\n",
    "\n",
    "```{list-table}\n",
    ":header-rows: 1\n",
    ":name: example-table\n",
    "* - dataset\n",
    "  - training(N)\n",
    "  - test(M)\n",
    "  - classes(k)\n",
    "  - channels(c)\n",
    "  - input size(d)\n",
    " * - MNIST\n",
    "   - 60K\n",
    "   - 10K\n",
    "   - 10\n",
    "   - GRAYSCALE\n",
    "   - 28*28\n",
    " * - CIFAR-10\n",
    "   - 50K\n",
    "   - 10K\n",
    "   - 10\n",
    "   - RGB\n",
    "   - 32*32\n",
    " * - CIFAR-100\n",
    "   - 50K\n",
    "   - 10K\n",
    "   - 10\n",
    "   - RGB\n",
    "   - 32*32\n",
    " * - ImageNet\n",
    "   - 1.2M\n",
    "   - 50K\n",
    "   - 1000\n",
    "   - RGB\n",
    "   - 224*224\n",
    "  ```\n",
    "### MNIST(Modified National Institute of Standards and Technology Database) \n",
    "\n",
    "#### This is a database for handwritten digits\n",
    "- Training set : N = 60,000\n",
    "- Test set : M = 10,000\n",
    "- Image size : d = 28 * 28 * 1 = 784\n",
    "- Classes: k = 10\n",
    "```{figure} ../figures/mnist2_1.png\n",
    ":name: mnist\n",
    "```\n",
    "### CIFAR \n",
    "\n",
    "#### CIFAR-10\n",
    "- Training set : N = 50,000\n",
    "- Test set : M = 10,000\n",
    "- Image size : d = 32 * 32 * 3\n",
    "- Classes: k = 10\n",
    "```{figure} ../figures/mnist1_1.png\n",
    ":name: cifar10\n",
    "```\n",
    "\n",
    "#### CIFAR-100\n",
    "- Training set : N = 50，000\n",
    "- Test set : M = 10，000\n",
    "- Image size : d = 32 * 32 * 3\n",
    "- Classes: k = 100\n",
    "```{figure} ../figures/mnist1_1.png\n",
    ":name: cifar100\n",
    "```\n",
    "### ImageNet \n",
    "\n",
    "- All data set: N + M = 1，431，167\n",
    "- Image size : d = 224 * 224 * 3\n",
    "- Classes: k = 1，000\n",
    "```{figure} ../figures/imagenet1_1.png\n",
    ":name: imagenet\n",
    "```\n",
    "```{figure} ../figures/imagenet1_2.png\n",
    ":name: mt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}